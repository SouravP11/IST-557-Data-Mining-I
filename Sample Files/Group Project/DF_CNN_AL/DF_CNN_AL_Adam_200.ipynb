{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import Statements"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, random_split\n","import numpy as np\n","import random\n","from sklearn.metrics import f1_score, recall_score\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{},"source":["Device Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["device: cuda:0\n"]}],"source":["# Set device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["Data Prep"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# Download and load the CIFAR-10 dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","train_set = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n","test_set = datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n","\n","# Split train data into train and validation\n","train_size = int(0.8 * len(train_set))\n","val_size = len(train_set) - train_size\n","train_dataset, val_dataset = random_split(train_set, [train_size, val_size])\n","\n","batch_size = 1024\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{},"source":["Random Seed"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to set a random seed for reproducibility\n","def set_seed(seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 10000)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    return seed"]},{"cell_type":"markdown","metadata":{},"source":["Validation"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Function for validation\n","def validate(net, val_loader, criterion):\n","    total_loss = 0.0\n","    with torch.no_grad():\n","        for data in val_loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","    return total_loss / len(val_loader)"]},{"cell_type":"markdown","metadata":{},"source":["Train Model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Function for training\n","def train_model(net, train_loader, val_loader, criterion, optimizer, epochs):\n","    train_losses = []\n","    val_losses = []\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","        \n","        train_losses.append(running_loss / len(train_loader))\n","        val_loss = validate(net, val_loader, criterion)\n","        val_losses.append(val_loss)\n","        print(f'Epoch {epoch + 1}, Train Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}')\n","\n","    return train_losses, val_losses"]},{"cell_type":"markdown","metadata":{},"source":["Metrics Calculation"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Function to calculate accuracy, F1 score, and recall\n","def calculate_metrics(net, loader):\n","    net.eval()\n","    correct = 0\n","    total = 0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predictions.extend(predicted.cpu().numpy())\n","\n","    accuracy = 100 * correct / total\n","    f1 = f1_score(all_labels, all_predictions, average='weighted')\n","    recall = recall_score(all_labels, all_predictions, average='weighted')\n","    return accuracy, f1, recall"]},{"cell_type":"markdown","metadata":{},"source":["Test Error Calculation"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Additional function to calculate test error\n","def calculate_test_error(net, test_loader):\n","    net.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    test_accuracy = 100 * correct / total\n","    return 100 - test_accuracy  # Test error"]},{"cell_type":"markdown","metadata":{},"source":["Model Architecture"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class ChannelAttention(nn.Module):\n","    def __init__(self, in_planes, ratio=16):\n","        super(ChannelAttention, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n","        self.fc1   = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n","        self.relu1 = nn.ReLU()\n","        self.fc2   = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n","        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n","        out = avg_out + max_out\n","        return self.sigmoid(out)\n","\n","def initialize_model(device):\n","    class DecentFitCNN(nn.Module):\n","        def __init__(self):\n","            super(DecentFitCNN, self).__init__()\n","            # Convolutional layers\n","            self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","            self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","\n","            # Channel Attention layers\n","            self.ca1 = ChannelAttention(32)\n","            self.ca2 = ChannelAttention(64)\n","            self.ca3 = ChannelAttention(128)\n","\n","            # Batch normalization layers\n","            self.bn1 = nn.BatchNorm2d(32)\n","            self.bn2 = nn.BatchNorm2d(64)\n","            self.bn3 = nn.BatchNorm2d(128)\n","\n","            # Max pooling, reduced to two layers\n","            self.pool = nn.MaxPool2d(2, 2)\n","\n","            # Dropout\n","            self.dropout = nn.Dropout(0.2)\n","\n","            # Adjusting the fully connected layer input size\n","            self.fc1 = nn.Linear(128 * 8 * 8, 512)  # Adjusted input size\n","            self.fc2 = nn.Linear(512, 256)\n","            self.fc3 = nn.Linear(256, 10)  # 10 classes in CIFAR-10\n","    \n","        def forward(self, x):\n","            # Convolutional layers with ReLU, batch normalization, and channel attention\n","            x = self.ca1(self.bn1(F.relu(self.conv1(x))))\n","            x = self.pool(x)\n","            x = self.ca2(self.bn2(F.relu(self.conv2(x))))\n","            x = self.pool(x)\n","            x = self.ca3(self.bn3(F.relu(self.conv3(x))))\n","            # Removed the third pooling layer\n","    \n","            # Flatten the tensor for the fully connected layers\n","            x = x.view(-1, 128 * 8 * 8)  # Adjusted flatten size\n","    \n","            # Fully connected layers with dropout\n","            x = F.relu(self.fc1(x))\n","            x = self.dropout(x)\n","            x = F.relu(self.fc2(x))\n","            x = self.fc3(x)\n","            return x\n","\n","    net = DecentFitCNN().to(device)\n","\n","    return net"]},{"cell_type":"markdown","metadata":{},"source":["Loss Function"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def initialize_loss_function():\n","    return nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{},"source":["Optimizer"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def initialize_optimizer(model_params):\n","    return optim.Adam(model_params, lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["Training the model for different seeds"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Run: 1\n","Seed: 2344\n"]},{"ename":"RuntimeError","evalue":"Given input size: (32x1x1). Calculated output size: (32x0x0). Output size is too small","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mc:\\PennState OneDrive\\OneDrive - The Pennsylvania State University\\CODE\\DF_CNN_AL\\DF_CNN_AL_Adam_200.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer \u001b[39m=\u001b[39m initialize_optimizer(model_params\u001b[39m=\u001b[39mnet\u001b[39m.\u001b[39mparameters())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Train the network\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m train_losses, val_losses \u001b[39m=\u001b[39m train_model(net, train_loader, val_loader, criterion, optimizer, epochs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Calculate metrics on validation and test sets\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m val_accuracy, val_f1, val_recall \u001b[39m=\u001b[39m calculate_metrics(net, val_loader)\n","\u001b[1;32mc:\\PennState OneDrive\\OneDrive - The Pennsylvania State University\\CODE\\DF_CNN_AL\\DF_CNN_AL_Adam_200.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32mc:\\PennState OneDrive\\OneDrive - The Pennsylvania State University\\CODE\\DF_CNN_AL\\DF_CNN_AL_Adam_200.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# Convolutional layers with ReLU, batch normalization, and channel attention\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/PennState%20OneDrive/OneDrive%20-%20The%20Pennsylvania%20State%20University/CODE/DF_CNN_AL/DF_CNN_AL_Adam_200.ipynb#X32sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\soura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:791\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> 791\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n","\u001b[1;31mRuntimeError\u001b[0m: Given input size: (32x1x1). Calculated output size: (32x0x0). Output size is too small"]}],"source":["# Run the training for 5 different seeds\n","epochs = 200\n","metrics = {\n","    'seed': [],\n","    'train_losses': [],\n","    'val_losses': [],\n","    'val_accuracy': [],\n","    'val_f1': [],\n","    'val_recall': [],\n","    'test_accuracy': [],\n","    'test_f1': [],\n","    'test_recall': []\n","}\n","\n","all_test_errors = []\n","\n","for run in range(5):\n","    print(f\"Run: {run + 1}\")\n","    seed = set_seed()\n","    print(f\"Seed: {seed}\")\n","\n","    # Reinitialize the model, loss function, and optimizer\n","    net = initialize_model(device=device)\n","    criterion = initialize_loss_function()\n","    optimizer = initialize_optimizer(model_params=net.parameters())\n","\n","    # Train the network\n","    train_losses, val_losses = train_model(net, train_loader, val_loader, criterion, optimizer, epochs)\n","\n","    # Calculate metrics on validation and test sets\n","    val_accuracy, val_f1, val_recall = calculate_metrics(net, val_loader)\n","    test_accuracy, test_f1, test_recall = calculate_metrics(net, test_loader)\n","    print(f\"Run {run+1} - Validation Accuracy: {val_accuracy}, F1: {val_f1}, Recall: {val_recall}\")\n","    print(f\"Run {run+1} - Test Accuracy: {test_accuracy}, F1: {test_f1}, Recall: {test_recall}\")\n","\n","    # Plot training and validation loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label='Training Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.title(f\"Training and Validation Loss for Run {run+1}\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","    \n","    # Calculate test error\n","    test_errors = [calculate_test_error(net, test_loader) for _ in train_losses]  # Assuming constant test error over epochs\n","    all_test_errors.append(test_errors)\n","    \n","    # Plot test error\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(test_errors, label='Test Error')\n","    plt.title(f\"Test Error for Run {run+1}\")\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Error (%)')\n","    plt.legend()\n","    plt.show()\n","    \n","    # Store metrics\n","    metrics['seed'].append(seed)\n","    metrics['train_losses'].append(train_losses)\n","    metrics['val_losses'].append(val_losses)\n","    metrics['val_accuracy'].append(val_accuracy)\n","    metrics['val_f1'].append(val_f1)\n","    metrics['val_recall'].append(val_recall)\n","    metrics['test_accuracy'].append(test_accuracy)\n","    metrics['test_f1'].append(test_f1)\n","    metrics['test_recall'].append(test_recall)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate mean and standard deviation across runs\n","mean_metrics = {metric: np.mean(metrics[metric]) for metric in metrics if metric not in ['seed', 'train_losses', 'val_losses']}\n","std_metrics = {metric: np.std(metrics[metric]) for metric in metrics if metric not in ['seed', 'train_losses', 'val_losses']}\n","\n","# Print mean metrics and standard deviation\n","print(\"Mean Metrics:\", mean_metrics)\n","print(\"Standard Deviation of Metrics:\", std_metrics)\n","\n","# Calculate mean test error across all runs\n","mean_test_errors = np.mean(all_test_errors, axis=0)\n","\n","# Plot mean test error\n","plt.figure(figsize=(10, 5))\n","plt.plot(mean_test_errors, label='Mean Test Error')\n","plt.title(\"Mean Test Error Across All Runs\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Error (%)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","\n","# Assume all_test_errors is a list of test errors for each run\n","test_error = all_test_errors[0]  # Selecting the test errors of the first run\n","\n","# Define the directory path where the file will be saved\n","directory_path = '../test_errors/'\n","\n","# Create the directory if it doesn't exist\n","os.makedirs(directory_path, exist_ok=True)\n","\n","# Save the test errors to a file in the specified directory\n","file_name = 'DF_CNN_AL_ADAM_200.pt'  # Name the file\n","torch.save(test_error, os.path.join(directory_path, file_name))\n","\n","# Providing the path where the file is saved\n","path_to_saved_file = os.path.join(directory_path, file_name)\n","print(\"Path to saved file:\", path_to_saved_file)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
