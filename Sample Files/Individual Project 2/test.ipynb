{"cells":[{"cell_type":"markdown","metadata":{"id":"jtGLhMX5Dqb-"},"source":["## Import Statements"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.373241Z","iopub.status.busy":"2023-10-29T03:00:56.372771Z","iopub.status.idle":"2023-10-29T03:00:56.379792Z","shell.execute_reply":"2023-10-29T03:00:56.378600Z","shell.execute_reply.started":"2023-10-29T03:00:56.373207Z"},"id":"3cymbevFDtaB","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["## Device Config"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.382384Z","iopub.status.busy":"2023-10-29T03:00:56.381797Z","iopub.status.idle":"2023-10-29T03:00:56.395469Z","shell.execute_reply":"2023-10-29T03:00:56.394587Z","shell.execute_reply.started":"2023-10-29T03:00:56.382351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Device is : cuda\n"]}],"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Device is : {device}\")"]},{"cell_type":"markdown","metadata":{"id":"Mr3yKeOHDvjx"},"source":["## Set the Seed for reproducibility"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.396968Z","iopub.status.busy":"2023-10-29T03:00:56.396681Z","iopub.status.idle":"2023-10-29T03:00:56.407923Z","shell.execute_reply":"2023-10-29T03:00:56.406814Z","shell.execute_reply.started":"2023-10-29T03:00:56.396944Z"},"id":"FrIxfehUDyvI","trusted":true},"outputs":[],"source":["# Set the random seed for reproducibility\n","seed = 42\n","torch.manual_seed(seed)\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"RxjqoAdoD1VY"},"source":["## Define number of folds"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.411438Z","iopub.status.busy":"2023-10-29T03:00:56.411039Z","iopub.status.idle":"2023-10-29T03:00:56.418162Z","shell.execute_reply":"2023-10-29T03:00:56.417310Z","shell.execute_reply.started":"2023-10-29T03:00:56.411401Z"},"id":"cPCIcmaeD3-f","trusted":true},"outputs":[],"source":["# Define the number of folds (k)\n","k = 5  # You can change this value as needed"]},{"cell_type":"markdown","metadata":{"id":"YCV9wC-fD5zX"},"source":["## CNN"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.419511Z","iopub.status.busy":"2023-10-29T03:00:56.419228Z","iopub.status.idle":"2023-10-29T03:00:56.431847Z","shell.execute_reply":"2023-10-29T03:00:56.431145Z","shell.execute_reply.started":"2023-10-29T03:00:56.419488Z"},"id":"rnul8ygSD714","trusted":true},"outputs":[],"source":["# Define your CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Flatten(),\n","            nn.Linear(512, 10)  # 10 classes for CIFAR-10\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"3IxlgUK5EFrY"},"source":["## Data Prep"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:56.433328Z","iopub.status.busy":"2023-10-29T03:00:56.433002Z","iopub.status.idle":"2023-10-29T03:00:57.384583Z","shell.execute_reply":"2023-10-29T03:00:57.383692Z","shell.execute_reply.started":"2023-10-29T03:00:56.433302Z"},"id":"og45j__PEHrl","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["# Define data augmentation and preprocessing transformations\n","batch_size = 20\n","augmentation_transform = transforms.Compose([\n","    transforms.RandomRotation(10),\n","    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load the CIFAR-10 dataset\n","augmented_train_data = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=augmentation_transform)\n","\n","# Split the dataset into k folds\n","fold_size = len(augmented_train_data) // k\n","fold_datasets = [torch.utils.data.Subset(augmented_train_data, range(i * fold_size, (i + 1) * fold_size)) for i in range(k)]\n","\n","# 10 classes in total\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"id":"l6-TOF-GFM1o"},"source":["## Test set"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:57.386119Z","iopub.status.busy":"2023-10-29T03:00:57.385763Z","iopub.status.idle":"2023-10-29T03:00:57.433021Z","shell.execute_reply":"2023-10-29T03:00:57.432079Z","shell.execute_reply.started":"2023-10-29T03:00:57.386083Z"},"id":"L2XS7W2WFOgR","trusted":true},"outputs":[],"source":["# load test data (note that the data has been transformed already)\n","test_images = torch.load('/kaggle/input/fall-2023-ist-557-individual-project-ii/test_image.pt')"]},{"cell_type":"markdown","metadata":{"id":"zLhvOPZUEQ9R"},"source":["## Training Loop"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T03:00:57.435188Z","iopub.status.busy":"2023-10-29T03:00:57.434654Z","iopub.status.idle":"2023-10-29T04:49:28.096385Z","shell.execute_reply":"2023-10-29T04:49:28.095299Z","shell.execute_reply.started":"2023-10-29T03:00:57.435143Z"},"id":"8k4IH8XLDlnz","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training fold 1/5\n"]},{"name":"stderr","output_type":"stream","text":["/home/rootsourav/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: /home/rootsourav/miniconda3/envs/tf/lib/python3.9/site-packages/torch/lib/../../nvidia/cudnn/lib/libcudnn_cnn_infer.so.8: undefined symbol: _Z22cudnnGenericOpTensorNdILi2EE13cudnnStatus_tP12cudnnContext16cudnnGenericOp_t21cudnnNanPropagation_tPK21cudnnActivationStructPKvPK17cudnnTensorStructS9_S9_SC_S9_S9_SC_Pv, version libcudnn_ops_infer.so.8 (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:78.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"ename":"RuntimeError","evalue":"GET was unable to find an engine to execute this computation","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32md:\\IST\\IST 557 - Data Mining - Techniques and Applications\\Sample Files\\Individual Project 2\\test.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32md:\\IST\\IST 557 - Data Mining - Techniques and Applications\\Sample Files\\Individual Project 2\\test.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/IST/IST%20557%20-%20Data%20Mining%20-%20Techniques%20and%20Applications/Sample%20Files/Individual%20Project%202/test.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"]}],"source":["# Lists to store performance metrics\n","all_fold_train_losses = []\n","all_fold_val_losses = []\n","\n","# Initialize your model\n","model = CNN()\n","model.to(device)\n","\n","for fold_idx, fold_data in enumerate(fold_datasets):\n","    print(f\"Training fold {fold_idx + 1}/{k}\")\n","\n","    # Create data loaders for training and validation\n","    validation_set = fold_data\n","    training_sets = [f for i, f in enumerate(fold_datasets) if i != fold_idx]\n","    training_set = torch.utils.data.ConcatDataset(training_sets)\n","\n","    train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=2)\n","    valid_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    \n","\n","    # Initialize optimizer and loss function\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","    # Training loop\n","    train_losses = []\n","    val_losses = []\n","    total_epoch = 50  # You can change the number of epochs as needed\n","\n","    for epoch in range(total_epoch):\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","\n","        # Train the model\n","        model.train()\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * data.size(0)\n","\n","        # Validate the model\n","        model.eval()\n","        for valid_data, valid_target in valid_loader:\n","            valid_data, valid_target = valid_data.to(device), valid_target.to(device)\n","            valid_output = model(valid_data)\n","            loss = criterion(valid_output, valid_target)\n","            valid_loss += loss.item() * valid_data.size(0)\n","\n","        avg_val_loss = valid_loss / len(validation_set)\n","        avg_train_loss = train_loss / len(training_set)\n","\n","        val_losses.append(avg_val_loss)\n","        train_losses.append(avg_train_loss)\n","\n","        print(f'Epoch: {epoch + 1}/{total_epoch} \\tTraining Loss: {avg_train_loss:.6f} \\tValidation Loss: {avg_val_loss:.6f}')\n","\n","    print(f'Finished Training for fold {fold_idx + 1}/{k}')\n","    all_fold_train_losses.append(train_losses)\n","    all_fold_val_losses.append(val_losses)\n","\n","# Calculate and print the average performance metrics over all folds\n","avg_train_losses = np.mean(all_fold_train_losses, axis=0)\n","avg_val_losses = np.mean(all_fold_val_losses, axis=0)\n","\n","# Plot the training and validation loss curves\n","import matplotlib.pyplot as plt\n","\n","plt.plot(range(1, total_epoch + 1), avg_train_losses, label='Average Train Loss', marker='o')\n","plt.plot(range(1, total_epoch + 1), avg_val_losses, label='Average Validation Loss', marker='o')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Average Training and Validation Loss Curves ({k}-fold cross-validation)')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-10-29T04:50:18.866313Z","iopub.status.busy":"2023-10-29T04:50:18.865895Z","iopub.status.idle":"2023-10-29T04:50:19.486973Z","shell.execute_reply":"2023-10-29T04:50:19.486049Z","shell.execute_reply.started":"2023-10-29T04:50:18.866282Z"},"id":"Q7YKagF7FUKJ","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>frog</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>truck</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>horse</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>ship</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>plane</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>bird</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["      label\n","0       cat\n","1       dog\n","2      frog\n","3       dog\n","4     truck\n","...     ...\n","4995  horse\n","4996   ship\n","4997  plane\n","4998    dog\n","4999   bird\n","\n","[5000 rows x 1 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# since now we're testing (not training), we set no_grad to NOT calculate the gradients\n","with torch.no_grad():\n","    test_images = test_images.to(device)\n","    # calculate outputs by running images through the network\n","    outputs = model(test_images)\n","    # the class with the highest probability is what we choose as prediction\n","    _, predicted = torch.max(outputs.data, 1)\n","    predicted = np.array([classes[i] for i in predicted])\n","\n","submission = pd.DataFrame()\n","submission['label'] = predicted\n","submission.to_csv(\"kFold_50.csv\", index=True, index_label='id')\n","submission"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
